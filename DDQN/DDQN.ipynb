{
 "cells": [
  {
   "cell_type": "code",
   "id": "e2b75d1a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-08T18:14:41.575643Z",
     "start_time": "2025-01-08T18:14:17.068897Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import gymnasium as gym\n",
    "import ale_py\n",
    "import cv2\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import HTML, display, clear_output\n",
    "from matplotlib import animation\n",
    "from collections import deque, defaultdict\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from random import random\n",
    "import os\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.models import Sequential, clone_model\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# To plot pretty figures\n",
    "#%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "\n",
    "import matplotlib.animation as animation\n",
    "mpl.rc('animation', html='jshtml')"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "0075b0dc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-08T18:14:53.889543Z",
     "start_time": "2025-01-08T18:14:53.884652Z"
    }
   },
   "source": [
    "def resize_frame(frame):\n",
    "    #frame = frame[30:-12,5:-4] # no need to crop\n",
    "    frame = np.average(frame,axis = 2) # convert to grayscale\n",
    "    frame = cv2.resize(frame,(84,84),interpolation = cv2.INTER_NEAREST) # resize to 84x84\n",
    "    frame = np.array(frame,dtype = np.uint8) # convert to uint8\n",
    "    return frame"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "4e6ac65c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-08T18:14:54.173562Z",
     "start_time": "2025-01-08T18:14:54.169088Z"
    }
   },
   "source": [
    "class Memory():\n",
    "    def __init__(self,max_len):\n",
    "        self.max_len = max_len\n",
    "        self.frames = deque(maxlen = max_len)\n",
    "        self.actions = deque(maxlen = max_len)\n",
    "        self.rewards = deque(maxlen = max_len)\n",
    "        self.done_flags = deque(maxlen = max_len)\n",
    "\n",
    "    def add_experience(self,next_frame, next_frames_reward, next_action, next_frame_terminal):\n",
    "        self.frames.append(next_frame)\n",
    "        self.actions.append(next_action)\n",
    "        self.rewards.append(next_frames_reward)\n",
    "        self.done_flags.append(next_frame_terminal)"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "id": "5f847ba1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-08T18:21:43.788120Z",
     "start_time": "2025-01-08T18:21:43.778357Z"
    }
   },
   "source": [
    "def initialize_new_game(name, env, agent):\n",
    "    \"\"\"We don't want an agents past game influencing its new game, so we add in some dummy data to initialize\"\"\"\n",
    "    \n",
    "    env.reset()\n",
    "    starting_frame = resize_frame(env.step(0)[0])\n",
    "\n",
    "    dummy_action = 0\n",
    "    dummy_reward = 0\n",
    "    dummy_done = False\n",
    "    for _ in range(3):\n",
    "        agent.memory.add_experience(starting_frame, dummy_reward, dummy_action, dummy_done)\n",
    "\n",
    "def make_env(name):\n",
    "    env = gym.make(name, render_mode='rgb_array')\n",
    "    # env = gym.make(name, frameskip=1, render_mode='rgb_array')\n",
    "    # env = gym.wrappers.AtariPreprocessing(env, frame_skip=4, screen_size=84)\n",
    "    return env\n",
    "\n",
    "def take_step(name, env, agent, score, lives, debug):\n",
    "    \n",
    "    #1 and 2: Update timesteps and save weights\n",
    "    agent.total_timesteps += 1\n",
    "    if agent.total_timesteps % 10000 == 0:\n",
    "      agent.model.save_weights('recent.weights.h5')\n",
    "      print('\\nWeights saved!')\n",
    "\n",
    "    #3: Take action\n",
    "    next_frame, next_frames_reward, next_frame_terminal, _, info = env.step(agent.memory.actions[-1])\n",
    "    next_lives = info['lives']\n",
    "\n",
    "    #4: Get next state\n",
    "    next_frame = resize_frame(next_frame)\n",
    "    new_state = [agent.memory.frames[-3], agent.memory.frames[-2], agent.memory.frames[-1], next_frame]\n",
    "    new_state = np.moveaxis(new_state,0,2)/255 #We have to do this to get it into keras's goofy format of [batch_size,rows,columns,channels]\n",
    "    new_state = np.expand_dims(new_state,0) #^^^\n",
    "    \n",
    "    #5: Get next action, using next state\n",
    "    next_action = agent.get_action(new_state)\n",
    "\n",
    "    #6: Now we add the next experience to memory\n",
    "    lost_life_penalty = 0 if lives == next_lives else -20\n",
    "    agent.memory.add_experience(next_frame, next_frames_reward + lost_life_penalty, next_action, next_frame_terminal)\n",
    "    \n",
    "    #7: If game is over, return the score\n",
    "    if next_frame_terminal:\n",
    "        return (score + next_frames_reward),True, next_lives\n",
    "\n",
    "    #8: If we are trying to debug this then render\n",
    "    if debug:\n",
    "        img = env.render()\n",
    "        global frames\n",
    "        frames.append(img)\n",
    "\n",
    "    #9: If the threshold memory is satisfied, make the agent learn from memory\n",
    "    if len(agent.memory.frames) > agent.starting_mem_len:\n",
    "        agent.learn(debug)\n",
    "\n",
    "    return (score + next_frames_reward),False, next_lives\n",
    "\n",
    "def play_episode(name, env, agent, debug = False):\n",
    "    initialize_new_game(name, env, agent)\n",
    "    done = False\n",
    "    score = 0\n",
    "    lives = 4\n",
    "    while True:\n",
    "        score, done, lives = take_step(name,env,agent,score, lives, debug)\n",
    "        if done:\n",
    "            break\n",
    "    return score"
   ],
   "outputs": [],
   "execution_count": 38
  },
  {
   "cell_type": "code",
   "id": "abc5c55a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-08T18:22:26.800103Z",
     "start_time": "2025-01-08T18:22:26.782640Z"
    }
   },
   "source": [
    "class Agent():\n",
    "    def __init__(self,possible_actions,starting_mem_len,max_mem_len,starting_epsilon,learn_rate, starting_lives = 4, debug = False):\n",
    "        self.memory = Memory(max_mem_len)\n",
    "        self.possible_actions = possible_actions\n",
    "        self.epsilon = starting_epsilon\n",
    "        self.epsilon_decay = .9/100000\n",
    "        self.epsilon_min = .05\n",
    "        self.gamma = .95\n",
    "        self.learn_rate = learn_rate\n",
    "        self.model = self._build_model()\n",
    "        self.model_target = clone_model(self.model)\n",
    "        self.total_timesteps = 0\n",
    "        self.lives = starting_lives\n",
    "        self.starting_mem_len = starting_mem_len\n",
    "        self.learns = 0\n",
    "\n",
    "\n",
    "    def _build_model(self):\n",
    "        model = Sequential()\n",
    "        model.add(Input((84,84,4)))\n",
    "        model.add(Conv2D(filters = 32,kernel_size = (8,8),strides = 4,data_format=\"channels_last\", activation = 'relu',kernel_initializer = tf.keras.initializers.VarianceScaling(scale=2)))\n",
    "        model.add(Conv2D(filters = 64,kernel_size = (4,4),strides = 2,data_format=\"channels_last\", activation = 'relu',kernel_initializer = tf.keras.initializers.VarianceScaling(scale=2)))\n",
    "        model.add(Conv2D(filters = 64,kernel_size = (3,3),strides = 1,data_format=\"channels_last\", activation = 'relu',kernel_initializer = tf.keras.initializers.VarianceScaling(scale=2)))\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(512,activation = 'relu', kernel_initializer = tf.keras.initializers.VarianceScaling(scale=2)))\n",
    "        model.add(Dense(len(self.possible_actions), activation = 'linear'))\n",
    "        optimizer = Adam(self.learn_rate)\n",
    "        model.compile(optimizer, loss=tf.keras.losses.Huber())\n",
    "        model.summary()\n",
    "        print('\\nAgent Initialized\\n')\n",
    "        return model\n",
    "\n",
    "    def get_action(self,state):\n",
    "        \"\"\"Explore\"\"\"\n",
    "        if np.random.rand() < self.epsilon:\n",
    "            return np.random.choice(self.possible_actions)\n",
    "\n",
    "        \"\"\"Do Best Acton\"\"\"\n",
    "        with tf.device(device):\n",
    "            a_index = np.argmax(self.model.predict(state, verbose=0))\n",
    "        return self.possible_actions[a_index]\n",
    "\n",
    "    def _index_valid(self,index):\n",
    "        if self.memory.done_flags[index-3] or self.memory.done_flags[index-2] or self.memory.done_flags[index-1] or self.memory.done_flags[index]:\n",
    "            return False\n",
    "        else:\n",
    "            return True\n",
    "\n",
    "    def learn(self,debug = False):\n",
    "        \"\"\"we want the output[a] to be R_(t+1) + Qmax_(t+1).\"\"\"\n",
    "        \"\"\"So target for taking action 1 should be [output[0], R_(t+1) + Qmax_(t+1), output[2]]\"\"\"\n",
    "\n",
    "        \"\"\"First we need 32 random valid indicies\"\"\"\n",
    "        states = []\n",
    "        next_states = []\n",
    "        actions_taken = []\n",
    "        next_rewards = []\n",
    "        next_done_flags = []\n",
    "\n",
    "        while len(states) < 32:\n",
    "            index = np.random.randint(4,len(self.memory.frames) - 1)\n",
    "            if self._index_valid(index):\n",
    "                state = [self.memory.frames[index-3], self.memory.frames[index-2], self.memory.frames[index-1], self.memory.frames[index]]\n",
    "                state = np.moveaxis(state,0,2)/255\n",
    "                next_state = [self.memory.frames[index-2], self.memory.frames[index-1], self.memory.frames[index], self.memory.frames[index+1]]\n",
    "                next_state = np.moveaxis(next_state,0,2)/255\n",
    "\n",
    "                states.append(state)\n",
    "                next_states.append(next_state)\n",
    "                actions_taken.append(self.memory.actions[index])\n",
    "                next_rewards.append(self.memory.rewards[index+1])\n",
    "                next_done_flags.append(self.memory.done_flags[index+1])\n",
    "\n",
    "        \"\"\"Now we get the ouputs from our model, and the target model. We need this for our target in the error function\"\"\"\n",
    "        with tf.device(device):\n",
    "            labels = self.model.predict(np.array(states), verbose=0)\n",
    "            next_state_values = self.model_target.predict(np.array(next_states), verbose=0)\n",
    "        \n",
    "        \"\"\"Now we define our labels, or what the output should have been\n",
    "           We want the output[action_taken] to be R_(t+1) + Qmax_(t+1) \"\"\"\n",
    "        for i in range(32):\n",
    "            action = self.possible_actions.index(actions_taken[i])\n",
    "            # since it is taken from memory, next_rewards is already adjusted for lost lives\n",
    "            labels[i][action] = next_rewards[i] + (not next_done_flags[i]) * self.gamma * max(next_state_values[i])\n",
    "\n",
    "        \"\"\"Train our model using the states and outputs generated\"\"\"\n",
    "        with tf.device(device):\n",
    "            self.model.fit(np.array(states),labels,batch_size = 32, epochs = 1, verbose = 0)\n",
    "\n",
    "        \"\"\"Decrease epsilon and update how many times our agent has learned\"\"\"\n",
    "        if self.epsilon > self.epsilon_min:\n",
    "            self.epsilon -= self.epsilon_decay\n",
    "        self.learns += 1\n",
    "        \n",
    "        \"\"\"Every 10000 learned (originally), copy our model weights to our target model\"\"\"\n",
    "        if self.learns % 10000 == 0:\n",
    "            self.model_target.set_weights(self.model.get_weights())\n",
    "            print('\\nTarget model updated')"
   ],
   "outputs": [],
   "execution_count": 44
  },
  {
   "cell_type": "code",
   "id": "07a5db66",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-08T18:23:13.299840Z",
     "start_time": "2025-01-08T18:23:13.293157Z"
    }
   },
   "source": [
    "def update_scene(num, frames, patch):\n",
    "    patch.set_data(frames[num])\n",
    "    return patch,\n",
    "\n",
    "def plot_animation(frames, repeat=False, interval=40):\n",
    "    fig = plt.figure()\n",
    "    patch = plt.imshow(frames[0])\n",
    "    plt.axis('off')\n",
    "    anim = animation.FuncAnimation(\n",
    "        fig, update_scene, fargs=(frames, patch),\n",
    "        frames=len(frames), repeat=repeat, interval=interval)\n",
    "    plt.close()\n",
    "    return anim"
   ],
   "outputs": [],
   "execution_count": 53
  },
  {
   "cell_type": "code",
   "id": "f6a7306a",
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2025-01-08T18:23:14.036707Z",
     "start_time": "2025-01-08T18:23:13.700629Z"
    }
   },
   "source": [
    "name = 'ALE/Pacman-v5'\n",
    "\n",
    "device = '/GPU:0' if tf.config.experimental.list_physical_devices('GPU') else '/CPU:0'\n",
    "\n",
    "agent = Agent(possible_actions=[0,1,2,3,4],starting_mem_len=50000,max_mem_len=750000,starting_epsilon = 1, learn_rate = .0005)\n",
    "gym.register_envs(ale_py)\n",
    "env = make_env(name)\n",
    "\n",
    "last_100_avg = [-41]\n",
    "scores = deque(maxlen = 100)\n",
    "all_scores = []\n",
    "max_score = -41\n",
    " \n",
    "env.reset()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001B[1mModel: \"sequential_10\"\u001B[0m\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_10\"</span>\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001B[1m \u001B[0m\u001B[1mLayer (type)                   \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mOutput Shape          \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1m      Param #\u001B[0m\u001B[1m \u001B[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_30 (\u001B[38;5;33mConv2D\u001B[0m)              │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m20\u001B[0m, \u001B[38;5;34m20\u001B[0m, \u001B[38;5;34m32\u001B[0m)     │         \u001B[38;5;34m8,224\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_31 (\u001B[38;5;33mConv2D\u001B[0m)              │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m9\u001B[0m, \u001B[38;5;34m9\u001B[0m, \u001B[38;5;34m64\u001B[0m)       │        \u001B[38;5;34m32,832\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_32 (\u001B[38;5;33mConv2D\u001B[0m)              │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m7\u001B[0m, \u001B[38;5;34m7\u001B[0m, \u001B[38;5;34m64\u001B[0m)       │        \u001B[38;5;34m36,928\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_10 (\u001B[38;5;33mFlatten\u001B[0m)            │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m3136\u001B[0m)           │             \u001B[38;5;34m0\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_20 (\u001B[38;5;33mDense\u001B[0m)                │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m512\u001B[0m)            │     \u001B[38;5;34m1,606,144\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_21 (\u001B[38;5;33mDense\u001B[0m)                │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m5\u001B[0m)              │         \u001B[38;5;34m2,565\u001B[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_30 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,224</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_31 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">32,832</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_32 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3136</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,606,144</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_21 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,565</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Total params: \u001B[0m\u001B[38;5;34m1,686,693\u001B[0m (6.43 MB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,686,693</span> (6.43 MB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Trainable params: \u001B[0m\u001B[38;5;34m1,686,693\u001B[0m (6.43 MB)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,686,693</span> (6.43 MB)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Non-trainable params: \u001B[0m\u001B[38;5;34m0\u001B[0m (0.00 B)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Agent Initialized\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]],\n",
       " \n",
       "        [[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]],\n",
       " \n",
       "        [[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]],\n",
       " \n",
       "        [[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]],\n",
       " \n",
       "        [[0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0],\n",
       "         [0, 0, 0]]], dtype=uint8),\n",
       " {'lives': 4, 'episode_frame_number': 16, 'frame_number': 32})"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 54
  },
  {
   "cell_type": "code",
   "id": "3f434621",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-08T18:23:14.898154Z",
     "start_time": "2025-01-08T18:23:14.894858Z"
    }
   },
   "source": [
    "# only when continuing training\n",
    "# if os.path.exists('recent.weights.h5'):\n",
    "#     agent.model.load_weights('recent.weights.h5')\n",
    "#     agent.model_target.load_weights('recent.weights.h5')\n",
    "#     print('\\nWeights loaded!')\n",
    "# else:\n",
    "#     print('\\nNo weights found')\n",
    "# agent.epsilon = 0 # Set the epsilon at the value you had when you stopped training"
   ],
   "outputs": [],
   "execution_count": 55
  },
  {
   "cell_type": "code",
   "id": "b44cf4c2",
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2025-01-08T19:05:32.432413Z",
     "start_time": "2025-01-08T18:23:20.326812Z"
    }
   },
   "source": [
    "for i in tqdm(range(15000)):\n",
    "    frames = [] # Saving the frames for the gif\n",
    "    timesteps = agent.total_timesteps\n",
    "    timee = time.time()\n",
    "    score = play_episode(name, env, agent, debug = True) #set debug to true for rendering\n",
    "    scores.append(score)\n",
    "    all_scores.append(score)\n",
    "    if score > max_score:\n",
    "        max_score = score\n",
    "\n",
    "    # print('\\nEpisode: ' + str(i))\n",
    "    # print('Steps: ' + str(agent.total_timesteps - timesteps))\n",
    "    # print('Duration: ' + str(time.time() - timee))\n",
    "    # print('Score: ' + str(score))\n",
    "    # print('Max Score: ' + str(max_score))\n",
    "    # print('Epsilon: ' + str(agent.epsilon))\n",
    "    \n",
    "    if i%50==0 and i!=0:\n",
    "        anim = plot_animation(frames)\n",
    "        anim.save(\"pacman{}.gif\".format(i), dpi=100, writer= animation.PillowWriter(fps=20))# Saving the gif\n",
    "        \n",
    "    if i%100==0 and i!=0:\n",
    "        last_100_avg.append(sum(scores)/len(scores))\n",
    "        plt.plot(np.arange(0,i+1,100),last_100_avg)\n",
    "        plt.show()"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 21/15000 [00:14<2:47:07,  1.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Weights saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 45/15000 [00:29<2:33:50,  1.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Weights saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 68/15000 [01:07<2:29:40,  1.66it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Weights saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 90/15000 [01:24<3:20:03,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Weights saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 100/15000 [01:31<2:46:41,  1.49it/s]"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 114/15000 [03:03<87:49:40, 21.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Weights saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 134/15000 [42:08<77:55:51, 18.87s/it]  \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[56], line 5\u001B[0m\n\u001B[0;32m      3\u001B[0m timesteps \u001B[38;5;241m=\u001B[39m agent\u001B[38;5;241m.\u001B[39mtotal_timesteps\n\u001B[0;32m      4\u001B[0m timee \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime()\n\u001B[1;32m----> 5\u001B[0m score \u001B[38;5;241m=\u001B[39m \u001B[43mplay_episode\u001B[49m\u001B[43m(\u001B[49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43menv\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43magent\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdebug\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m \u001B[38;5;66;03m#set debug to true for rendering\u001B[39;00m\n\u001B[0;32m      6\u001B[0m scores\u001B[38;5;241m.\u001B[39mappend(score)\n\u001B[0;32m      7\u001B[0m all_scores\u001B[38;5;241m.\u001B[39mappend(score)\n",
      "Cell \u001B[1;32mIn[38], line 66\u001B[0m, in \u001B[0;36mplay_episode\u001B[1;34m(name, env, agent, debug)\u001B[0m\n\u001B[0;32m     64\u001B[0m lives \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m4\u001B[39m\n\u001B[0;32m     65\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[1;32m---> 66\u001B[0m     score, done, lives \u001B[38;5;241m=\u001B[39m \u001B[43mtake_step\u001B[49m\u001B[43m(\u001B[49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\u001B[43menv\u001B[49m\u001B[43m,\u001B[49m\u001B[43magent\u001B[49m\u001B[43m,\u001B[49m\u001B[43mscore\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlives\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdebug\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     67\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m done:\n\u001B[0;32m     68\u001B[0m         \u001B[38;5;28;01mbreak\u001B[39;00m\n",
      "Cell \u001B[1;32mIn[38], line 56\u001B[0m, in \u001B[0;36mtake_step\u001B[1;34m(name, env, agent, score, lives, debug)\u001B[0m\n\u001B[0;32m     54\u001B[0m \u001B[38;5;66;03m#9: If the threshold memory is satisfied, make the agent learn from memory\u001B[39;00m\n\u001B[0;32m     55\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(agent\u001B[38;5;241m.\u001B[39mmemory\u001B[38;5;241m.\u001B[39mframes) \u001B[38;5;241m>\u001B[39m agent\u001B[38;5;241m.\u001B[39mstarting_mem_len:\n\u001B[1;32m---> 56\u001B[0m     \u001B[43magent\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlearn\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdebug\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     58\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m (score \u001B[38;5;241m+\u001B[39m next_frames_reward),\u001B[38;5;28;01mFalse\u001B[39;00m, next_lives\n",
      "Cell \u001B[1;32mIn[44], line 76\u001B[0m, in \u001B[0;36mAgent.learn\u001B[1;34m(self, debug)\u001B[0m\n\u001B[0;32m     74\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Now we get the ouputs from our model, and the target model. We need this for our target in the error function\"\"\"\u001B[39;00m\n\u001B[0;32m     75\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m tf\u001B[38;5;241m.\u001B[39mdevice(device):\n\u001B[1;32m---> 76\u001B[0m     labels \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpredict\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43marray\u001B[49m\u001B[43m(\u001B[49m\u001B[43mstates\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m     77\u001B[0m     next_state_values \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel_target\u001B[38;5;241m.\u001B[39mpredict(np\u001B[38;5;241m.\u001B[39marray(next_states), verbose\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m)\n\u001B[0;32m     79\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Now we define our labels, or what the output should have been\u001B[39;00m\n\u001B[0;32m     80\u001B[0m \u001B[38;5;124;03m   We want the output[action_taken] to be R_(t+1) + Qmax_(t+1) \"\"\"\u001B[39;00m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    115\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    116\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 117\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    118\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    119\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:497\u001B[0m, in \u001B[0;36mTensorFlowTrainer.predict\u001B[1;34m(self, x, batch_size, verbose, steps, callbacks)\u001B[0m\n\u001B[0;32m    492\u001B[0m \u001B[38;5;129m@traceback_utils\u001B[39m\u001B[38;5;241m.\u001B[39mfilter_traceback\n\u001B[0;32m    493\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mpredict\u001B[39m(\n\u001B[0;32m    494\u001B[0m     \u001B[38;5;28mself\u001B[39m, x, batch_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, verbose\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mauto\u001B[39m\u001B[38;5;124m\"\u001B[39m, steps\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, callbacks\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    495\u001B[0m ):\n\u001B[0;32m    496\u001B[0m     \u001B[38;5;66;03m# Create an iterator that yields batches of input data.\u001B[39;00m\n\u001B[1;32m--> 497\u001B[0m     epoch_iterator \u001B[38;5;241m=\u001B[39m \u001B[43mTFEpochIterator\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    498\u001B[0m \u001B[43m        \u001B[49m\u001B[43mx\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    499\u001B[0m \u001B[43m        \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbatch_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    500\u001B[0m \u001B[43m        \u001B[49m\u001B[43msteps_per_epoch\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msteps\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    501\u001B[0m \u001B[43m        \u001B[49m\u001B[43mshuffle\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m    502\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdistribute_strategy\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdistribute_strategy\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    503\u001B[0m \u001B[43m        \u001B[49m\u001B[43msteps_per_execution\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msteps_per_execution\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    504\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    506\u001B[0m     \u001B[38;5;66;03m# Container that configures and calls callbacks.\u001B[39;00m\n\u001B[0;32m    507\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(callbacks, callbacks_module\u001B[38;5;241m.\u001B[39mCallbackList):\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:715\u001B[0m, in \u001B[0;36mTFEpochIterator.__init__\u001B[1;34m(self, distribute_strategy, *args, **kwargs)\u001B[0m\n\u001B[0;32m    713\u001B[0m \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    714\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_distribute_strategy \u001B[38;5;241m=\u001B[39m distribute_strategy\n\u001B[1;32m--> 715\u001B[0m dataset \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdata_adapter\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_tf_dataset\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    716\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(dataset, tf\u001B[38;5;241m.\u001B[39mdistribute\u001B[38;5;241m.\u001B[39mDistributedDataset):\n\u001B[0;32m    717\u001B[0m     dataset \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_distribute_strategy\u001B[38;5;241m.\u001B[39mexperimental_distribute_dataset(\n\u001B[0;32m    718\u001B[0m         dataset\n\u001B[0;32m    719\u001B[0m     )\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\array_data_adapter.py:124\u001B[0m, in \u001B[0;36mArrayDataAdapter.get_tf_dataset\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    111\u001B[0m num_full_batches \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mint\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_samples \u001B[38;5;241m/\u001B[39m\u001B[38;5;241m/\u001B[39m batch_size)\n\u001B[0;32m    113\u001B[0m \u001B[38;5;66;03m# Vectorized version of shuffle.\u001B[39;00m\n\u001B[0;32m    114\u001B[0m \u001B[38;5;66;03m# This is a performance improvement over using `from_tensor_slices`.\u001B[39;00m\n\u001B[0;32m    115\u001B[0m \u001B[38;5;66;03m# The indices of the data are shuffled and batched, and these indices\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    121\u001B[0m \u001B[38;5;66;03m# 4. optimized permutation batching\u001B[39;00m\n\u001B[0;32m    122\u001B[0m \u001B[38;5;66;03m# 5. disabled static optimizations\u001B[39;00m\n\u001B[1;32m--> 124\u001B[0m indices_dataset \u001B[38;5;241m=\u001B[39m \u001B[43mtf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdata\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mDataset\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrange\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m    126\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mpermutation\u001B[39m(_):\n\u001B[0;32m    127\u001B[0m     \u001B[38;5;66;03m# It turns out to be more performant to make a new set of indices\u001B[39;00m\n\u001B[0;32m    128\u001B[0m     \u001B[38;5;66;03m# rather than reusing the same range Tensor. (presumably because of\u001B[39;00m\n\u001B[0;32m    129\u001B[0m     \u001B[38;5;66;03m# buffer forwarding.)\u001B[39;00m\n\u001B[0;32m    130\u001B[0m     indices \u001B[38;5;241m=\u001B[39m tf\u001B[38;5;241m.\u001B[39mrange(num_samples, dtype\u001B[38;5;241m=\u001B[39mtf\u001B[38;5;241m.\u001B[39mint64)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:1022\u001B[0m, in \u001B[0;36mDatasetV2.range\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m   1018\u001B[0m \u001B[38;5;66;03m# Loaded lazily due to a circular dependency (dataset_ops -> range_op ->\u001B[39;00m\n\u001B[0;32m   1019\u001B[0m \u001B[38;5;66;03m# -> dataset_ops).\u001B[39;00m\n\u001B[0;32m   1020\u001B[0m \u001B[38;5;66;03m# pylint: disable=g-import-not-at-top,protected-access\u001B[39;00m\n\u001B[0;32m   1021\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdata\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mops\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m range_op\n\u001B[1;32m-> 1022\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mrange_op\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_range\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\range_op.py:25\u001B[0m, in \u001B[0;36m_range\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     24\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_range\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):  \u001B[38;5;66;03m# pylint: disable=unused-private-name\u001B[39;00m\n\u001B[1;32m---> 25\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_RangeDataset\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\data\\ops\\range_op.py:35\u001B[0m, in \u001B[0;36m_RangeDataset.__init__\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m     33\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_parse_args(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m     34\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_structure \u001B[38;5;241m=\u001B[39m tensor_spec\u001B[38;5;241m.\u001B[39mTensorSpec([], \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_output_type)\n\u001B[1;32m---> 35\u001B[0m variant_tensor \u001B[38;5;241m=\u001B[39m \u001B[43mgen_dataset_ops\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrange_dataset\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m     36\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstart\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_start\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     37\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstop\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_stop\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     38\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstep\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_step\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     39\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_common_args\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     40\u001B[0m \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__init__\u001B[39m(variant_tensor)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\ops\\gen_dataset_ops.py:6304\u001B[0m, in \u001B[0;36mrange_dataset\u001B[1;34m(start, stop, step, output_types, output_shapes, metadata, replicate_on_split, name)\u001B[0m\n\u001B[0;32m   6302\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m tld\u001B[38;5;241m.\u001B[39mis_eager:\n\u001B[0;32m   6303\u001B[0m   \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m-> 6304\u001B[0m     _result \u001B[38;5;241m=\u001B[39m \u001B[43mpywrap_tfe\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mTFE_Py_FastPathExecute\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   6305\u001B[0m \u001B[43m      \u001B[49m\u001B[43m_ctx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mRangeDataset\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstart\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstop\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstep\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43moutput_types\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m   6306\u001B[0m \u001B[43m      \u001B[49m\u001B[43moutput_types\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43moutput_shapes\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moutput_shapes\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmetadata\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmetadata\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   6307\u001B[0m \u001B[43m      \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mreplicate_on_split\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreplicate_on_split\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   6308\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m _result\n\u001B[0;32m   6309\u001B[0m   \u001B[38;5;28;01mexcept\u001B[39;00m _core\u001B[38;5;241m.\u001B[39m_NotOkStatusException \u001B[38;5;28;01mas\u001B[39;00m e:\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 56
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "198f8e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.model.save_weights('recent.weights.h5')\n",
    "agent.model_target.save_weights('recent_target.weights.h5')\n",
    "print('\\nWeights saved!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d6aa7a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot all scores obtained\n",
    "plt.plot(np.arange(len(all_scores)),all_scores)\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Score')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rl-project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
